未だに複雑なプログラミングが出来ないので、力技でやっつけたの備忘録。
一部、半角文字がエスケープされて保存出来ないので全角文字で残しているので注意。
（＜と￥が全角である）

使ったもの
    awk（gawk＋おーくの友だち）
    正規表現で検索・置換の出来るテキストエディタ


手順を記しておく
●対象のサイトのソースをローカルに保存する。


●テキストエディタで置換処理する
    検索ワード：<
    置換ワード：\n<

これでHTMLソース内で使用するタグの＜から＞までが一行に分解された。これを次のステップに持っていく。
空行が出来るが次の手順では全く無視するので気にしないこと。


●ここからawkの出番。
往々にして正規表現記述の方が処理が速いので下記の様にしてみた。これでsrc=でURLが記された行のみが抽出される。BEGINでIGNORECASE = 1;にしているのは、大文字小文字を区別しない為の設定。
BEGIN{
    IGNORECASE = 1;
    }
/src=/{
          print $0;
    }
END{
    }


●次に本当に画像ファイル名が記された行だけを抽出する為拡張子を指定。（.jsが残っていた）
BEGIN{
    IGNORECASE = 1;
    }
/(jpg|jpeg|gif)/{
    print $0;
    }
END{
    }


●ファイルPATHよりも前の不要部分を削除する為の正規表現置換（行頭から”まで削除しちゃう）
    検索ワード：^.*(src=|SRC=)"
    置換ワード：


●ファイルPATHよりも後ろの不要部分を削除する為の正規表現置換（”から行末まで削除しちゃう）
    検索ワード：".*$
    置換ワード：


●URLの記述がルートパス、相対パスのパターンを調整する。
絶対パス（httpから始まる）の場合は言うまでもなくそのままでOKなので何もしない。
具体的にはテキストエディタで正規表現マッチングで2パターンの置換を実行
パターン1：行頭が/の場合
パターン2：行頭が./の場合
    検索ワード：^/
    置換ワード：http://example.com/

    検索ワード：^￥./
    置換ワード：http://example.com/targetdir/


●ソートする
重複行の有無を把握する為にsortコマンドをコマンドプロンプトで実行する。
これで画像のURLがソートされた。
    C:\sort soruce.txt > sorted.txt


●重複行の削除はどうするか？
UNIX系だとsortしてからuniqコマンドで容易に重複削除出来るけど、Windowsにはuniqコマンドが無い。
cygwinを入れてるならUNIXコマンドが使えて楽勝だけど。
awkで組めなくはないだろうけどスクリプトを組むのがしんどいのでやりたくない。
という訳でwindows上で動くcmdファイルを作成（ネットで拾ってきた）して実行する。
    c:\uniq.cmd sorted.txt uniq.txt


-----uniq.cmd-----中身はなんと下記3行だけ。テキストファイルで作成した後に拡張子をcmdに変更する。
    @echo off
    type nul >%2
    for /f "delims=" %%I in (%1) do findstr /X /C:"%%I" %2 >NUL || (echo;%%I)>>%2
-----uniq.cmd-----

結局、uniq.cmdはどうしてこれでuniq処理出来るかわからんが目的は達成出来た。
http://scripting.cocolog-nifty.com/blog/2009/09/uniq-77dd.html